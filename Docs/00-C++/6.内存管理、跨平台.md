## 内存

### 内存的堆与栈

### 内存的优化

> **CPU缓存**
>
> 在[计算机](https://baike.baidu.com/item/计算机)系统中，**CPU高速缓存**（英语：CPU Cache，在本文中简称缓存）是用于减少[处理器](https://baike.baidu.com/item/处理器)访问内存所需平均时间的部件。在金字塔式存储体系中它位于自顶向下的第二层，仅次于CPU寄存器。其容量远小于[内存](https://baike.baidu.com/item/内存)，但速度却可以接近处理器的频率。
>
> 当处理器发出内存访问请求时，会先查看缓存内是否有请求数据。如果存在（命中），则不经访问内存直接返回该数据；如果不存在（失效），则要先把内存中的相应数据载入缓存，再将其返回处理器。
>
> 缓存之所以有效，主要是因为程序运行时对内存的访问呈现局部性（Locality）特征。这种局部性既包括空间局部性（Spatial Locality），也包括时间局部性（Temporal Locality）。有效利用这种局部性，缓存可以达到极高的命中率。
>
> 在处理器看来，缓存是一个透明部件。因此，程序员通常无法直接干预对缓存的操作。但是，确实可以根据缓存的特点对程序代码实施特定优化，从而更好地利用缓存。
>
> —— 摘自百度百科《[CPU缓存](https://baike.baidu.com/item/CPU%E7%BC%93%E5%AD%98)》



- 缓存不友好

  ```c++
  #include <iostream>
  #include <chrono>
  #include <vector>
  
  class ClockGuard {
  public:
  	ClockGuard(const std::string& inDest)
  		:mDesc(inDest)
  	{
  		mStartTime = std::chrono::steady_clock::now();
  	}
  	~ClockGuard() {
  		std::chrono::steady_clock::time_point currentTime = std::chrono::steady_clock::now();
  		double durationNs = std::chrono::duration<double, std::nano>(currentTime - mStartTime).count();
  		std::cout << mDesc << " Cost: " << durationNs << " Ns" << std::endl;
  	}
  private:
  	std::string mDesc;
  	std::chrono::steady_clock::time_point mStartTime;
  };
  
  const size_t bigger_than_cachesize = 10 * 1024 * 1024;
  long* ptr = new long[bigger_than_cachesize];
  void ClearCPUCache() {
  	for (int i = 0; i < bigger_than_cachesize; i++)
  	{
  		ptr[i] = rand();
  	}
  }
  
  
  int main(int argc,char** argv) {
  	std::vector<int*> continuous(1000);
  	std::vector<int*> dispersive(1000);
  
  	for (int*& item : continuous) {		//内存连续的数组
  		item = new int;
  	}
  
  	const int split_number = 10000;	   //调整该数以查看cache的影响
  	for (int*& item : dispersive) {		//内存分散的数组
  		item = new int[split_number];
  	}
  
  	ClearCPUCache();
  	{
  		ClockGuard guard("continuous");
  		for (int*& item : continuous) {
  			*item = 1;
  		}
  	}
  	ClearCPUCache();
  	{
  		ClockGuard guard("dispersive");
  		for (int*& item : dispersive) {
  			*item = 1;
  		}
  	}
  
  	return 0;
  }
  ```

- 锁的碰撞

  ```c++
  #include <iostream>
  #include <chrono>
  #include <thread>
  #include <mutex>
  #include <functional>
  
  class ClockGuard {
  public:
  	ClockGuard(const std::string& inDest)
  		:mDesc(inDest)
  	{
  		mStartTime = std::chrono::steady_clock::now();
  	}
  	~ClockGuard() {
  		std::chrono::steady_clock::time_point currentTime = std::chrono::steady_clock::now();
  		double durationNs = std::chrono::duration<double, std::nano>(currentTime - mStartTime).count();
  		std::cout << mDesc << " Cost: " << durationNs << " Nanosecond" << std::endl;
  	}
  private:
  	std::string mDesc;
  	std::chrono::steady_clock::time_point mStartTime;
  };
  
  const int number_of_threadwork = 10;
  
  int counter = 0;
  int offset_without_thread_local = 5;
  thread_local int offset_with_thread_local = 5;
  
  const size_t bigger_than_cachesize = 10 * 1024 * 1024;
  long* ptr = new long[bigger_than_cachesize];
  void ClearCPUCache() {
  	for (int i = 0; i < bigger_than_cachesize; i++)
  	{
  		ptr[i] = rand();
  	}
  }
  
  
  class ThreadWorkGroup{
  public:
  	ThreadWorkGroup(std::function<void()> opertation) {
  		std::thread threads[number_of_threadwork];
  		for (auto& thread : threads) {
  			thread = std::thread([this, opertation]() {	
  				for (int i = 0; i < 10000; i++) {
  					opertation();
  				}
  				mCompletedCounter++;
  				mCv.notify_one();
  			});
  			thread.detach();
  		}
  		std::unique_lock<std::mutex> lock(mCounterMutex);
  		mCv.wait(lock, [this]() {return mCompletedCounter == number_of_threadwork; });
  	}
  private:
  	std::mutex mCounterMutex;
  	std::atomic<int> mCompletedCounter = 0;
  	std::condition_variable mCv;
  };
  
  int main(int argc,char** argv) {
  	{
  		ClockGuard guard("With thread local");
  		ThreadWorkGroup work([] {
  			counter += offset_with_thread_local;
  			});
  	}
  
  	{
  		ClockGuard guard("Without thread local");
  		ThreadWorkGroup work([] {
  			counter += offset_without_thread_local;
  		});
  	}
  
  	return 0;
  }
  ```



UE4拥有自己的内存管理器，使之能够独立管理、加速、跟踪内存，并内存对齐以支持多个平台。

![img](https://img2020.cnblogs.com/blog/78946/202104/78946-20210405155329825-609161482.png)

## OS级内存分配API

- Windows

  ```C++
  LPVOID WINAPI VirtualAlloc(...);
  BOOL WINAPI VirtualFree(...);
  ```

- Unix及Mac

  ```c++
  void* mmap(...)
  bool  munmap(...)
  ```

## FMalloc(内存分配器)

> FMalloc的定义位于UnrealEngine\Engine\Source\Runtime\Core\Public\HAL\MemoryBase.h

#### 基类

- FUseSystemMallocForNew：重载了类的new、delete运算符，避免使用new FMalloc出现递归分配的问题。
- FExec：用于处理控制台指令。

#### 通用接口

- `void* Malloc( SIZE_T, uint32 Alignment=DEFAULT_ALIGNMENT )`：内存分配函数
- `void* TryMalloc( SIZE_T Count, uint32 Alignment=DEFAULT_ALIGNMENT )`：与Malloc不同的是，分配失败可能返回`nullptr`
- `void* Realloc( void* Original, SIZE_T Count, uint32 Alignment=DEFAULT_ALIGNMENT )`：重分配函数
- `void* TryRealloc(void* Original, SIZE_T Count, uint32 Alignment=DEFAULT_ALIGNMENT)`：与Realloc不同的是，分配失败可能返回`nullptr`，并且Original所指向的内存将仍然有效
- `void Free( void* Original ) `：内存销毁函数
- `SIZE_T QuantizeSize(SIZE_T Count, uint32 Alignment)`：对于某些分配器来说，这将返回应该被请求消除内部碎片的实际大小。 返回值总是>= Count。 这可以用来扩大和缩小容器到最佳尺寸。 这个调用总是快速且线程安全的，没有锁。  
- `bool GetAllocationSize(void *Original, SIZE_T &SizeOut)`：给定地址分配的内存大小 。
- `void Trim(bool bTrimThreadCaches)`：尽可能多释放内存。 必须从主线程调用。  
- `void SetupTLSCachesOnCurrentThread()`：在当前线程上设置TLS缓存。
- `void ClearAndDisableTLSCachesOnCurrentThread()`：清除当前线程上的TLS缓存，并禁用任何未来的缓存。  
- `bool IsInternallyThreadSafe() const `：用于说明该分配器是否是线程安全，如果不是线程安全，可能会采用其他内存分配器
- `bool ValidateHeap()：`验证堆分配器

#### 分配器类型

FMalloc的子类通过实现上述接口，直接操作OS级别的内存分配API，完成不同的分配策略，其中主要有：

> UnrealEngine\Engine\Source\Runtime\Core\Private\HAL文件下以Malloc开头的文件

- **Ansi**：标准的c分配器，直接调用malloc、free、realloc。

  > 对于windows平台，启用了[低碎片堆](https://docs.microsoft.com/en-us/windows/win32/memory/low-fragmentation-heap?redirectedfrom=MSDN)功能

- **Stomp**：有助于追踪分配过程中读写造成的问题，如野指针，内存越界等。

  > Stomp 在释放物理内存的同时保留了虚拟地址范围。释放内存后在其他地方使用相同的指针，则会抛出异常。因此当你想跟踪一些问题时，它可能会有效，但它同样具有副作用，关联虚拟地址和物理地址的OS页表会消耗大量内存。

- **TBB**：Thread Building Blocks，Intel提供的64位可伸缩内存分配器

  > **英特尔® 线程构建模块 | 英特尔® 软件** https://software.intel.com/en-us/tbb

- **Jemalloc**：主要用于 Unix 的内存分配器。

  >**jemalloc** http://jemalloc.net/
  >**jemalloc / jemalloc** https://github.com/jemalloc/jemalloc

- **Binned**：装箱内存分配器，主要用于IOS。

  - **Binned**：

    > 装箱分配器将一块内存（**Pool**）划分为许多不同大小的槽位，比如Binned在PC上把64KB划分成41个不同的槽位，从尾部往前分配空闲槽位：
    >
    > ```
    > static const uint32 BlockSizes[POOL_COUNT] = {
    >   16,   32,   48,   64,   80,   96,   112,  128,
    >   160,  192,  224,  256,  288,  320,  384,  448,
    >   512,  576,  640,  704,  768,  896,  1024, 1168,
    >   1360, 1632, 2048, 2336, 2720, 3264, 4096, 4672,
    >   5456, 6544, 8192, 9360, 10912,  13104,  16384,  21840,  32768
    > };
    > ```

  - **Binned2**：Binned2分配器支持线程本地内存分配，不需要每次都加锁。这在频繁小块内存分配、释放时可以提升不少性能。

  - **Binned3**：使用虚拟内存地址（逻辑内存地址），可以通过排列它来高速执行Pool的Index搜索，以便可以从内存的指针计算出目标大小的Pool 。

- **Mimalloc**：一个优于 tcmalloc 和 jemalloc 的通用内存分配器

  > Github https://github.com/microsoft/mimalloc
  >
  > MS Research https://www.microsoft.com/en-us/research/publication/mimalloc-free-list-sharding-in-action/

#### 不同平台对内存分配器的支持情况

|              | **Ansi** | **TBB**® | **Jemalloc**® | **Binned** | **Binned2** | **Binned3** | **Mimalloc**® | **Stomp** |
| :----------: | :------: | :------: | :-----------: | :--------: | :---------: | :---------: | :-----------: | :-------: |
| **Android**  |    √     |          |               |     √      |   default   | √（64bits） |               |           |
|   **IOS**    |    √     |          |               |  default   |             |             |               |           |
| **Windows**  |    √     | defalut  |               |     √      |      √      | √（64bits） |       √       |     √     |
|  **Linux**   |    √     |          |       √       |     √      |   default   |             |               |     √     |
|   **Mac**    |    √     | default  |               |     √      |      √      |             |               |     √     |
| **HoloLens** |    √     |          |               |            |             |   default   |               |           |

## FGenericPlatformMemory（平台内存管理类）

>UnrealEngine\Engine\Source\Runtime\Core\Public\GenericPlatform\GenericPlatformMemory.h

不同平台都有对应的平台内存管理类，它们继承自FGenericPlatformMemory，存储着平台相关的内存信息，并提供函数接口BaseAllocator()创建内存分配器

#### 平台实现

- FAndroidPlatformMemory
- FApplePlatformMemory
- FIOSPlatformMemory
- FWindowsPlatformMemory
- FLinuxPlatformMemory
- FUnixPlatformMemory
- FMacPlatformMemory

#### BaseAllocator

各个平台通过实现`static FMalloc* FGenericPlatformMemory::BaseAllocator()`，创建平台相应的FMalloc类型，

> 以**Windows**为例，其实现位于`UnrealEngine\Engine\Source\Runtime\Core\Public\Windows\WindowsPlatformMemory.h`

## 应用层

#### FMemory（内存管理接口）

**FMemory**用于对**FMalloc**的全局实例**(GMalloc)**和**FGenericPlatformMemory**的接口进行封装，提供一系列供用户直接使用的静态函数来操纵内存，包括但不限于：`Malloc`、`Realloc`、`Free`、`Memmove`、`Memcmp`、`Memset`、`Memcpy`...

#### new delete（全局运算符重写）

`UnrealEngine\Engine\Source\Runtime\Core\Public\Modules\Boilerplate\ModuleBoilerplate.h`中对全局new delete进行重写，使之转接到FMemory::Malloc，样例如下

```c++
void* operator new[]( size_t Size) OPERATOR_NEW_THROW_SPEC { return FMemory::Malloc( Size ? Size : 1 ); } 
```

#### Allocator（分配代理）

> UnrealEngine\Engine\Source\Runtime\Core\Public\Containers\ContainerAllocationPolicies.h

之前称FMalloc为内存分配器，而Allocator的职责则偏向于分配策略。UE中具有以下的分配策略：

- **TAlignedHeapAllocator\<Aligment>**：依据对齐的堆栈分配代理
- **TSizedHeapAllocator\<IndexSize>**：依据size的堆栈分配代理
- **TInlineAllocator\<NumInlineElements, SecondaryAllocator >**：超出最大元素数量的部分会使用次级分配代理进行分配。

- **TNonRelocatableInlineAllocator\<NumInlineElements>**：允许存储指向其内联元素的指针，其次级堆分配代理可实现TInlineAllocator。
- **TFixedAllocator\<NumInlineElements>**：固定分配代理在同一次分配中最多分配指定数量的元素，与内联分配代理不同的是，超出部分不使用次级分配。  
- **TSparseArrayAllocator\<InElementAllocator,InBitArrayAllocator>**：单一类型的稀疏数组分配代理
- **TInlineSparseArrayAllocator<NumInlineElements, SecondaryAllocator> **：允许对一组元素的内联分配大小进行调整的稀疏数组分配代理
- **TFixedSparseArrayAllocator\<NumInlineElements>**：与inline分配器不同的是，它不支持次级分配代理
- **TSetAllocator<···>**：单一类型的集合分配代理
- **TInlineSetAllocator<···>**：允许指定内联分配大小和次级分配
- **TFixedSetAllocator<···>**：只允许指定内联分配大小

#### UE4容器

> UnrealEngine\Engine\Source\Runtime\Core\Public\Containers\ContainersFwd.h

- **TArray**：TSizedHeapAllocator<32>
- **TArray64**：TSizedHeapAllocator<64>
- **TSet**：TSetAllocator<>
- **TMap**：TSetAllocator<>
- **TMultiMap**：TSetAllocator<>
- **TSortedMap**：TSizedHeapAllocator<32>
- **FString**：内含TArray\<TCHAR>
- **TByteArray、 TConstSetBitIterator、TConstDualSetBitIterator、TScriptBitArray**：TInlineAllocator<4>  
- **TSparseArray、FScriptSparseArray **：TSparseArrayAllocator<>

#### UObject

UE4为UObject使用了特定的内存分配策略**FUObjectAllocator**，其中提供了以下接口：

> UnrealEngine\Engine\Source\Runtime\CoreUObject\Public\UObject\UObjectAllocator.h

```C++
/**
* Allocates a UObjectBase from the free store or the permanent object pool
*
* @param Size size of uobject to allocate
* @param Alignment alignment of uobject to allocate
* @param bAllowPermanent if true, allow allocation in the permanent object pool, if it fits
* @return newly allocated UObjectBase (not really a UObjectBase yet, no constructor like thing has been called).
*/
UObjectBase* AllocateUObject(int32 Size, int32 Alignment, bool bAllowPermanent);

/**
* Returns a UObjectBase to the free store, unless it is in the permanent object pool
*
* @param Object object to free
*/
void FreeUObject(UObjectBase *Object) const;
```

全局实例**GUObjectAllocator**，在`UnrealEngine\Engine\Source\Runtime\CoreUObject\Private\UObject\.Class.cpp`中使用该实例创建以及销毁**UObejct**

## 开源内存分配框架

### [mimalloc](https://github.com/microsoft/mimalloc)

mimalloc是一种通用分配器，具有出色的[性能](https://github.com/microsoft/mimalloc#performance)特征。最初由 Daan Leijen 为[Koka](https://koka-lang.github.io/)和[Lean](https://github.com/leanprover/lean)语言的运行时系统开发 。

#### 优势

- **小而一致**：该库使用简单且一致的数据结构，大约有 8k LOC。这使得它非常适合集成和适应其他项目。对于运行时系统，它提供了用于单调*心跳*和延迟释放的钩子（对于具有引用计数的有界最坏情况时间）。
- **空闲列表分片**：每个“mimalloc 页”有许多较小的列表，而不是一个大的空闲列表（每个大小类），这减少了碎片并增加了局部性——及时分配的东西在内存中分配得很近。（一个 mimalloc 页包含一个大小级别的块，在 64 位系统上通常是 64KiB）。
- **自由列表多分片**：好主意！我们不仅将每个 mimalloc 页面的空闲列表分片，而且对于每个页面，我们都有多个空闲列表。特别是，有一个用于线程本地`free`操作的列表，另一个用于并发`free` 操作。从另一个线程中释放现在可以是单个 CAS，而无需线程之间的复杂协调。由于将有数千个单独的空闲列表，争用自然分布在堆上，并且在单个位置上竞争的机会将很低——这与跳过列表等随机算法非常相似，其中添加随机预言机消除了需要对于更复杂的算法。
- **急切页面重置**：当“页面”变空时（由于空闲列表分片的机会增加），内存被标记为操作系统未使用（“重置”或“清除”）减少（真实）内存压力和碎片，特别是在长时间运行的程序。
- **安全**: *mimalloc*可以在安全模式下构建，添加保护页、随机分配、加密空闲列表等，以防止各种堆漏洞。性能损失通常比我们的基准平均高出 10% 左右。
- **一流的堆**：有效地创建和使用多个堆来跨不同区域进行分配。堆可以一次销毁，而不是单独释放每个对象。
- **有界**：它不会受到*膨胀* 的影响，有界最坏情况分配时间 ( *wcat* )，有界空间开销（约 0.2% 元数据，分配大小最多浪费 12.5%），并且没有内部点仅使用原子操作的争用。
- **快速**：在我们的基准测试中， *mimalloc*优于其他领先的分配器（*jemalloc*、*tcmalloc*、*Hoard*等），并且通常使用更少的内存。一个不错的特性是它在广泛的基准测试中始终表现良好。对于较大的服务器程序，也有很好的巨大操作系统页面支持。

### [oneTBB](https://www.intel.com/content/www/us/en/developer/tools/oneapi/onetbb.html)

英特尔® oneAPI 线程构建块 (oneTBB) 是一个灵活的性能库，即使您不是线程专家，也可以简化为跨加速架构的复杂应用程序添加并行性的工作。

#### 特征

- **指定逻辑性能，而不是线程**
  运行时库自动将逻辑并行映射到线程上，从而最有效地利用处理器资源。
- **以线程为目标提高性能**
  专注于并行化计算密集型工作的特定目标，提供更高级别、更简单的解决方案。
- **与其他线程包共存  **
  它能够与其他线程无缝兼容，使您可以灵活地保持旧代码不变，并使用 oneTBB 进行新的实现。
- **强调可扩展的数据并行编程**
  oneTBB 强调数据并行编程，而不是将程序分解成功能块并为每个功能块分配一个单独的线程，从而使多个线程能够在集合的不同部分上工作。通过将集合分成更小的部分，这可以很好地扩展到更多的处理器。随着您添加处理器和加速器，程序性能会提高。

### [jemalloc](https://github.com/jemalloc/jemalloc)

jemalloc 是一个通用的`malloc(3)`实现，它强调避免碎片化和可扩展的并发支持。它旨在用作系统提供的内存分配器，如在 FreeBSD 的 libc 库中，以及用于链接到 C/C++ 应用程序。jemalloc 提供了许多超出标准分配器功能的内省、内存管理和调整功能。

### [tcmalloc](https://github.com/google/tcmalloc)

TCMalloc 是 Google 对 C`malloc()`和 C++ 的自定义实现，`operator new`用于C 和 C++ 代码中的分配内存。此自定义内存分配框架是 C 标准库（在 Linux 上通常通过`glibc`）和 C++ 标准库提供框架的替代方案。

#### 优势

- 性能随应用程序的并行程度提升
- 依附于C++14 和 C++17 进行了优化，并且在保证性能优势的情况下与标准略有不同（这些在[TCMalloc 参考](https://github.com/google/tcmalloc/blob/master/docs/reference.md)中注明）
- 允许在某些架构下提高性能的扩展，以及其他行为，例如指标收集

#### 特性

- 通过管理特定大小的内存块（称为“页面”）从操作系统执行分配。
- 将单独的页面（或在 TCMalloc 中称为“跨度”的页面运行）用于特定的对象大小。例如，所有 16 字节的对象都放置在专门为该大小的对象分配的“跨度”中。在这种情况下获取或释放内存的操作要简单得多。
- 将内存保存在*缓存中*以加快对常用对象的访问。如果以后重新分配此类内存，即使在释放后保留此类缓存也有助于避免代价高昂的系统调用。

## 如何应用

![](./Resource/UE4内存体系.png)

### Malloc的选择

UE程序在不同平台具有唯一的底层内存分配器，其中PC端默认使用oneTBB，移动端是UE内置的Binned分配器，由于要实现一套完整的内存分配框架需要投入大量的人力与精力，所以摆在我们面前的其实只有一条路——开源库。

在[mimalloc](https://github.com/microsoft/mimalloc)的基准测试中，它的各项性能指数在大多数情况下比[jemalloc](https://github.com/jemalloc/jemalloc) 和 [tcmalloc ](https://github.com/google/tcmalloc)更为优越，它是一个不错的选择。

在C++17的基础上，想要应用及替换一套内存分配框架是很容易的事情——只需覆盖operator new/delete。

下面是应用mimalloc的例子：

```C++
#include <vcruntime_new.h>

_NODISCARD _Ret_notnull_ _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL  operator new  (size_t Size) { return mi_malloc(Size ? Size : 1); }

_NODISCARD _Ret_notnull_ _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new[](size_t Size) { return mi_malloc(Size ? Size : 1); }

_NODISCARD _Ret_maybenull_ _Success_(return != NULL) _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new  (size_t Size, const std::nothrow_t&) { return mi_malloc(Size ? Size : 1); }

_NODISCARD _Ret_maybenull_ _Success_(return != NULL) _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new[](size_t Size, const std::nothrow_t&) { return mi_malloc(Size ? Size : 1); }

void __CRTDECL operator delete  (void* Ptr) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, size_t Size) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, size_t Size) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, size_t Size, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, size_t Size, const std::nothrow_t&) { mi_free(Ptr); }

_NODISCARD _Ret_notnull_ _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new  (size_t Size, std::align_val_t Alignment) { return mi_malloc_aligned(Size ? Size : 1, (std::size_t)Alignment); }

_NODISCARD _Ret_notnull_ _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new[](size_t Size, std::align_val_t Alignment) { return mi_malloc_aligned(Size ? Size : 1, (std::size_t)Alignment); }

_NODISCARD _Ret_maybenull_ _Success_(return != NULL) _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new  (size_t Size, std::align_val_t Alignment, const std::nothrow_t&) { return mi_malloc_aligned(Size ? Size : 1, (std::size_t)Alignment); }

_NODISCARD _Ret_maybenull_ _Success_(return != NULL) _Post_writable_byte_size_(_Size) _VCRT_ALLOCATOR
void* __CRTDECL operator new[](size_t Size, std::align_val_t Alignment, const std::nothrow_t&) { return mi_malloc_aligned(Size ? Size : 1, (std::size_t)Alignment); }

void __CRTDECL operator delete  (void* Ptr, std::align_val_t Alignment) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, std::align_val_t Alignment) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, std::align_val_t Alignment, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, std::align_val_t Alignment, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, size_t Size, std::align_val_t Alignment) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, size_t Size, std::align_val_t Alignment) { mi_free(Ptr); }
void __CRTDECL operator delete  (void* Ptr, size_t Size, std::align_val_t Alignment, const std::nothrow_t&) { mi_free(Ptr); }
void __CRTDECL operator delete[](void* Ptr, size_t Size, std::align_val_t Alignment, const std::nothrow_t&) { mi_free(Ptr); }
```

### Allocator的选择

#### [EASTL]()

EASTL（EA 标准模板库）旨在成为一个模板库，它包含并扩展C++ STL 的 功能，同时对很多游戏开发有用的方式进行了改进，并强调性能高于一切。EASTL 的大部分设计与标准 STL 相同，与标准STL实现不同的主要领域基本如下：

- EASTL 具有简化且更灵活的自定义分配方案。
- EASTL 的代码更易于阅读。
- EASTL 有扩展容器和算法。
- EASTL 具有专为游戏开发而设计的优化。

在上述各项中，唯一与 STL 不兼容的区别是内存分配的情况。

#### [foonathan](https://github.com/foonathan/memory)

foonathan也是为了解决STL存在的缺陷，但与EASTL不同，它并没有尝试更改 STL。

#### [STL C++17 polymorphic memory source](https://www.rkaiser.de/wp-content/uploads/2021/03/embo2021-pmr-STL-for-Embedded-Applications-en.pdf)

在C++17以前，完成STL容器的内存分配需要借助allocator，它主要有以下缺陷：

- allocator是模板签名的一部分，不同allocator的容器，无法混用

  ```c++
  vector<int,allocator0> v0;
  vector<int,allocator1> v1;
  v0 = v1;  //Error
  ```

- allocator内存对齐无法控制，需要传入自定义allocator

- allocator没有内部状态

C++17中为容器提供了新的内存分配方法 ——` <memory_resource>`

它的用法就像是下面这样：

```C++
#include <memory_resource>
#include <vector>
#include <string>            
#include <iostream>

class CustomMemoryResource :public std::pmr::memory_resource{   //自定义memory_source
public:
    CustomMemoryResource() {}
private:
    virtual void* do_allocate(const size_t _Bytes, const size_t _Align) override {
        return ::operator new(_Bytes,std::align_val_t(_Align));
    }                                                                                                                                             
    virtual void do_deallocate(void* _Ptr, size_t _Bytes, size_t _Align){
        ::operator delete(_Ptr,_Bytes, std::align_val_t(_Align));
    };
    virtual bool do_is_equal(const memory_resource& _That) const noexcept {
        return this==&_That;
    };
};
int main() {
    std::pmr::unsynchronized_pool_resource ms1; //非线程安全的池分配器
    std::pmr::synchronized_pool_resource ms2;   //同步池分配器
    CustomMemoryResource custom_memory_source;  //自定义分配器
    char buffer[20];
    std::pmr::monotonic_buffer_resource mbr(std::data(buffer),std::size(buffer),&custom_memory_source);   //单调缓存分配器，从buffer中分配内存，直到调用mbr.release()内存才会释放，超出缓存会使用上级分配器进行分配
    {
        std::pmr::vector<std::pmr::string> vec{ &mbr };
        vec.push_back("Hello World");
        vec.push_back("One Two Three");
    }   //vec 的内存不会释放
    mbr.release();  //此时才会释放mbr中的内存
}
```

从上面的代码可以看出**MemoryResouce**完美解决了**allocator**存在的问题，我们只需使用来自于命名空间`std::pmr`的容器。

它是怎么做到的呢？

以`std::pmr::vector`为例，找到它的定义：

```C++
namespace pmr {
    template <class _Ty>
    using vector = std::vector<_Ty, polymorphic_allocator<_Ty>>;
} // namespace pmr
```

非常简单，它只是一个使用了`polymorphic_allocator`的`std::vector`，找到它定义，可以发现如下代码：

```C++
template <class _Ty>
class polymorphic_allocator {
public:
    //...
    _NODISCARD __declspec(allocator) _Ty* allocate(_CRT_GUARDOVERFLOW const size_t _Count) {
        // get space for _Count objects of type _Ty from _Resource
        void* const _Vp = _Resource->allocate(_Get_size_of_n<sizeof(_Ty)>(_Count), alignof(_Ty));
        return static_cast<_Ty*>(_Vp);
    }

    void deallocate(_Ty* const _Ptr, const size_t _Count) noexcept /* strengthened */ {
        // return space for _Count objects of type _Ty to _Resource
        // No need to verify that size_t can represent the size of _Ty[_Count].
        _Resource->deallocate(_Ptr, _Count * sizeof(_Ty), alignof(_Ty));
        
private:
    memory_resource* _Resource = _STD pmr::get_default_resource();    
};
```

不难发现它其实只是在原来的Allocator接口上调用memory_resource的方法。

### 需要做什么？

确定好malloc和allocator之后，主要需要完成的是特定应用场景的优化，其中包括但不限于以下内容：

- 为特定应用场景实现memory_resouce
- 在特定场景使用最优的容器，由于STL的容器类型有限，可考虑接入Boost库来弥补这部分空缺（侵入式(Intrusive)容器、定长(Fixed)容器能极大程度的优化内存使用）

## 参考资料

[[UE4\] Memory Allocationについて - Qiita](https://qiita.com/EGJ-Yutaro_Sawada/items/4983d0ebfa945611d324)

[UE4内存分配器概述 - 可可西 - 博客园](https://www.cnblogs.com/kekec/p/12012537.html)

[UE4 Gamedev Guide - Allocators malloc](https://ikrima.dev/ue4guide/engine-programming/memory/allocators-malloc/)

[游戏引擎开发新感觉！(6) c++17内存管理](https://zhuanlan.zhihu.com/p/96089089)
